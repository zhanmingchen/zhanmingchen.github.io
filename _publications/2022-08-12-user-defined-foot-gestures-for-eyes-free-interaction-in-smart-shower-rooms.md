---
title: "User-Defined Foot Gestures for Eyes-Free Interaction in Smart Shower Rooms"
collection: publications
permalink: /publication/2022-08-12-user-defined-foot-gestures-for-eyes-free-interaction-in-smart-shower-rooms
excerpt: 'We conducted a three-phase study to explore foot-gesture-based interaction to achieve eyes-free interaction in smart shower rooms.'
date: 2022-08-12
venue: 'International Journal of Human–Computer Interaction'
paperurl: 'https://www.tandfonline.com/doi/full/10.1080/10447318.2022.2109260'
citation: 'Zhanming Chen, Huawei Tu, and Huiyue Wu. 2022. User-Defined Foot Gestures for Eyes-Free Interaction in Smart Shower Rooms. <i>International Journal of Human–Computer Interaction</i> 39, 20 (December 2023), 4139–4161. https://doi.org/10.1080/10447318.2022.2109260'
---

## Abstract

With the rapid development of natural human-computer interaction technologies, gesture-based interfaces have become popular. Although gesture interaction has received extensive attention from both academia and industry, most existing studies focus on hand gesture input, leaving foot-gesture-based interfaces underexplored, especially in scenarios where the user’s hands are occupied for other interaction tasks such as washing the hair in smart shower rooms. In such scenarios, users often have to perform interactive tasks (e.g., controlling water volume) with their eyes closed when water and shampoo liquid flow along with their head to eyes area. One possible way to address this problem is to use eyes-free (rather than eyes-engaged), foot-gesture-based interactive techniques that allow users to interact with the smart shower system without visual involvement. Through our online survey, 71.60% of the participants (58/81) have the requirements of using foot-gesture-based eyes-free interactions during showers. To this end, we conducted a three-phase study to explore foot-gesture-based interaction to achieve eyes-free interaction in smart shower rooms. We first derived a set of user-defined foot gestures for eyes-free interaction in smart shower rooms. Then, we proposed a taxonomy for foot gesture interaction. Our findings indicated that end-users preferred single-foot (76.1%), atomic (73.3%), deictic (65.0%), and dynamic (76.1%) foot gestures, which markedly differs from the results reported by previous studies on user-defined hand gestures. In addition, most of the user-defined dynamic foot gestures involve atomic movements perpendicular to the ground (40.1%) or parallel to the ground (27.7%). We finally distilled a set of concrete guidelines for foot gesture interfaces based on observing end-users’ mental model and behaviors when interacting with foot gestures. Our research can inform the design and development of foot-gesture-based interaction techniques for applications such as smart homes, intelligent vehicles, VR games, and accessibility design.

<p align="center">
  <img src="https://www.tandfonline.com/cms/asset/229d8a2b-60f8-4971-acf5-5b50179c9ae3/hihc_a_2109260_f0001_c.jpg" width="400">
</p>

> Online access: [https://www.tandfonline.com/doi/full/10.1080/10447318.2022.2109260](https://www.tandfonline.com/doi/full/10.1080/10447318.2022.2109260)
